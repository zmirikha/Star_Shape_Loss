import torch
import torch.nn as nn
import torch.nn.functional as F


def gen_b(img):
    """
     convolve the img with 8 pre-defined regional kernels of size (2m+1)*(2m+1)
     (m is equal to 6) and return the concatenation of the resulting maps.
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    filter_1 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_1 = filter_1.to(device)

    pad = nn.ReflectionPad2d(6)
    img = pad(img.unsqueeze(0))

    """
    Convolve the image with the Kernel. Examine how the pixel p value is
    close to its m closest pixels on the line segment connecting p to center.
    """

    b_1 = F.conv2d(img, filter_1, padding=0)
    del filter_1

    filter_2 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, -1, -1, -1, -1, -1, -1],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_2 = filter_2.to(device)

    b_2 = F.conv2d(img, filter_2, padding=0)
    del filter_2

    filter_3 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1]]).view(1, 1, 13, 13)

    filter_3 = filter_3.to(device)
    b_3 = F.conv2d(img, filter_3, padding=0)
    del filter_3

    filter_4 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_4 = filter_4.to(device)

    b_4 = F.conv2d(img, filter_4, padding=0)
    del filter_4

    filter_5 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_5 = filter_5.to(device)

    b_5 = F.conv2d(img, filter_5, padding=0)
    del filter_5

    filter_6 = torch.Tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [-1, -1, -1, -1, -1, -1, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_6 = filter_6.to(device)

    b_6 = F.conv2d(img, filter_6, padding=0)
    del filter_6

    filter_7 = torch.Tensor([[-1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_7 = filter_7.to(device)
    b_7 = F.conv2d(img, filter_7, padding=0)
    del filter_7

    filter_8 = torch.Tensor([[0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]).view(1, 1, 13, 13)

    filter_8 = filter_8.to(device)

    b_8 = F.conv2d(img, filter_8, padding=0)
    del filter_8

    b = torch.cat((b_1, b_2, b_3, b_4, b_5, b_6, b_7, b_8), 0)

    return b
